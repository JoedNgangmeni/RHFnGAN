{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1104226353.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[92], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    import pandas as pd, numpy as np,\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys, os, math, time\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import outputDataAggregator as agg\n",
    "import dataVisualizer as vis\n",
    "import myStructure as my\n",
    "import adabooster as myBoost\n",
    "import globalStuff as glbl\n",
    "import pandas as pd, numpy as np, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joedngangmeni/Documents/school/Research/RHF_Share/RHFnGAN/Code/AdaBoost\n"
     ]
    }
   ],
   "source": [
    "base_dir = base_dir = os.getcwd()  # Gets the directory where your script is\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You entered 'yes'. Beginning test run sequence...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "focusParentDir, focusDataDir, MAX_RUNS, ESTNUM, DEPTH, topNUM = my.paramDecider('ADA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDataPath = os.path.abspath(os.path.join(base_dir, '..', '..', f'{focusParentDir}', 'RawData', f'{focusDataDir}'))\n",
    "aggDataPath = os.path.abspath(os.path.join(base_dir, '..', '..', f'{focusParentDir}', 'AggData',f'{focusDataDir}'))\n",
    "graphsPath = os.path.abspath(os.path.join(base_dir, '..', '..', f'{focusParentDir}', 'Graphs',f'{focusDataDir}'))\n",
    "tablesPath = os.path.abspath(os.path.join(base_dir, '..', '..', f'{focusParentDir}', 'Tables',f'{focusDataDir}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inputDataParser as parse\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "X, y = parse.getAirData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMTREES = 5\n",
    "DEPTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=3), n_estimators=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=3), n_estimators=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=3)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=3)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=3), n_estimators=5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True)\n",
    "\n",
    "base_estimator = DecisionTreeRegressor(max_depth=DEPTH)\n",
    "\n",
    "ada = AdaBoostRegressor(estimator=base_estimator, n_estimators=NUMTREES)\n",
    "\n",
    "# print(f'X_train head:\\t{X_train.columns}\\ny_train head:\\t{y_train}\\nX_test head:\\t{X_test.columns}\\ny_test head:\\t{y_test}\\n')\n",
    "# Train the model\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regBoostingStats(data: pd.DataFrame, answers: np.array):\n",
    "    staged_predictions = ada.staged_predict(data)\n",
    "\n",
    "    r2, mse, rmse, mae = [], [], [], []\n",
    "    for stage, y_pred in enumerate(staged_predictions):\n",
    "        # Calculate R2\n",
    "        \n",
    "        r2.append(r2_score(answers, y_pred))\n",
    "        \n",
    "        # Calculate MSE\n",
    "        mse.append(mean_squared_error(answers, y_pred))\n",
    "\n",
    "        # Calculate MAE\n",
    "        mae.append(mean_absolute_error(answers, y_pred))\n",
    "    \n",
    "    for num in mse:\n",
    "        rmse.append(math.sqrt(num))\n",
    "    \n",
    "    return r2, rmse, mse, mae \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23523.388885143224, 23523.388885143224, 21533.371624352974, 21530.91158994749, 20829.376469963183]\n",
      "[153.37336432752338, 153.37336432752338, 146.742535157169, 146.73415277278664, 144.32385966971358]\n",
      "[22880.703553101746, 22880.703553101746, 20330.074016495513, 21045.07127304066, 20684.7247621654]\n",
      "[151.26368881229146, 151.26368881229146, 142.5835685361238, 145.06919477628824, 143.8218507813239]\n"
     ]
    }
   ],
   "source": [
    "r2_train, rmse_train, mse_train, mae_train = regBoostingStats(X_train, y_train)\n",
    "r2_test, rmse_test, mse_test, mae_test = regBoostingStats(X_test, y_test)\n",
    "\n",
    "\n",
    "print(mse_train)\n",
    "print(rmse_train)\n",
    "print(mse_test)\n",
    "print(rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clsBoostingStats(data: pd.DataFrame, answers: np.array):\n",
    "    staged_predictions = ada.staged_predict(data)\n",
    "\n",
    "    mlogloss, f1, accuracy, precision, recall  = [], [], [], [], []\n",
    "\n",
    "    for stage, y_pred in enumerate(staged_predictions):\n",
    "        f1.append(f1_score(answers, y_pred, average='weighted' , zero_division=0))\n",
    "        accuracy.append(accuracy_score(answers, y_pred))\n",
    "        precision.append(precision_score(answers, y_pred, average=\"weighted\", zero_division=0))\n",
    "        recall.append(recall_score(answers, y_pred, average='weighted', zero_division=0))\n",
    "\n",
    "        # Calculate multi-logloss\n",
    "        y_pred_proba = ada.staged_predict_proba(data)  \n",
    "        mlogloss.append(log_loss(answers, y_pred_proba, labels=ada.classes_))  \n",
    "\n",
    "    \n",
    "    return f1, accuracy, precision, recall, mlogloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, z = parse.getHARData()\n",
    "\n",
    "Z_train, Z_test, j_train, j_test = train_test_split(Y, z, test_size=0.30, shuffle=True)\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth=DEPTH)\n",
    "\n",
    "ada = AdaBoostClassifier(estimator=base_estimator, n_estimators=NUMTREES)\n",
    "\n",
    "# print(f'X_train head:\\t{X_train.columns}\\ny_train head:\\t{y_train}\\nX_test head:\\t{X_test.columns}\\ny_test head:\\t{y_test}\\n')\n",
    "# Train the model\n",
    "# ada.fit(Z_train, j_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joedngangmeni/anaconda3/envs/TRF/lib/python3.11/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AdaBoostClassifier' object has no attribute 'n_classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m elapsed_times \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Timing the AdaBoost fitting process for each round\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_stage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_stage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mada\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstaged_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mada\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstaged_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Fit AdaBoost model for one round\u001b[39;49;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/TRF/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:740\u001b[0m, in \u001b[0;36mAdaBoostClassifier.staged_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return staged predictions for X.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \n\u001b[1;32m    720\u001b[0m \u001b[38;5;124;03mThe predicted class of an input sample is computed as the weighted mean\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;124;03m    The predicted classes.\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    738\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m--> 740\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_classes_\u001b[49m\n\u001b[1;32m    741\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AdaBoostClassifier' object has no attribute 'n_classes_'"
     ]
    }
   ],
   "source": [
    "# Lists to store elapsed time for each round\n",
    "elapsed_times = []\n",
    "\n",
    "# Timing the AdaBoost fitting process for each round\n",
    "for stage, (X_train_stage, y_train_stage) in enumerate(zip(ada.staged_predict(Z_train), ada.staged_predict(j_train))):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fit AdaBoost model for one round\n",
    "    ada.fit(X_train_stage, y_train_stage)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    elapsed_times.append(elapsed_time)\n",
    "\n",
    "    print(f\"Round {stage + 1} - Elapsed Time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joedngangmeni/anaconda3/envs/TRF/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'y_pred' parameter of log_loss must be an array-like. Got <generator object AdaBoostClassifier.staged_predict_proba at 0x1785e6020> instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f1_train, accuracy_train, precision_train, recall_train, mlogloss_train \u001b[38;5;241m=\u001b[39m \u001b[43mclsBoostingStats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m f1_test, accuracy_test, precision_test, recall_test, mlogloss_test \u001b[38;5;241m=\u001b[39m clsBoostingStats(Z_test, j_test)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(f1_train)\n",
      "Cell \u001b[0;32mIn[89], line 14\u001b[0m, in \u001b[0;36mclsBoostingStats\u001b[0;34m(data, answers)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Calculate multi-logloss\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m ada\u001b[38;5;241m.\u001b[39mstaged_predict_proba(data)  \n\u001b[0;32m---> 14\u001b[0m     mlogloss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlog_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mada\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m)  \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f1, accuracy, precision, recall, mlogloss\n",
      "File \u001b[0;32m~/anaconda3/envs/TRF/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:204\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    202\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 204\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[1;32m    206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/envs/TRF/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:96\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'y_pred' parameter of log_loss must be an array-like. Got <generator object AdaBoostClassifier.staged_predict_proba at 0x1785e6020> instead."
     ]
    }
   ],
   "source": [
    "# f1_train, accuracy_train, precision_train, recall_train, mlogloss_train = clsBoostingStats(Z_train, j_train)\n",
    "# f1_test, accuracy_test, precision_test, recall_test, mlogloss_test = clsBoostingStats(Z_test, j_test)\n",
    "\n",
    "\n",
    "# print(f1_train)\n",
    "# print(f1_test)\n",
    "# print(mlogloss_train)\n",
    "# print(mlogloss_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TRF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
